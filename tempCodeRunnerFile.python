import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from langchain.llms import Groq
from langchain.prompts import PromptTemplate
from langchain.document_loaders import JSONLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from scipy.stats import chi2_contingency, ttest_ind, spearmanr
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix

# Load JSON file using LangChain JSONLoader
file_path = "Verifast_assignment_raw_data.json"
loader = JSONLoader(file_path, jq_schema=".[] | {event: .event, timestamp: .properties.time, customer_id: .properties.customer_id, url: .properties.payload.context.href, product_title: .properties.payload.data.productVariant.product.title}")
documents = loader.load()

# Convert JSON data to Pandas DataFrame
df = pd.DataFrame([doc.metadata for doc in documents])

# Convert timestamp to datetime format
df["timestamp"] = pd.to_datetime(df["timestamp"], unit="s")

# --- INDUSTRY BENCHMARKING ---
industry_cart_abandonment = 70  # Industry standard in %
industry_conversion_rate = 2.5  # Industry average conversion rate in %

# Conversion Funnel Analysis
conversion_counts = df["event"].value_counts()
cart_abandonment_rate = (conversion_counts.get("product_added_to_cart", 0) - conversion_counts.get("checkout_completed", 0)) / conversion_counts.get("product_added_to_cart", 1) * 100

# Returning Users vs First-Time Users
returning_users = df["customer_id"].duplicated().sum()
total_users = df["customer_id"].nunique()
returning_user_rate = (returning_users / total_users) * 100

# --- PREDICTIVE MODELING: PURCHASE LIKELIHOOD ---
df['checkout'] = df['event'].apply(lambda x: 1 if x == "checkout_completed" else 0)
user_features = df.groupby("customer_id").agg(
    total_interactions=('event', 'count'),
    product_views=('product_title', 'count'),
    cart_additions=('event', lambda x: (x == "product_added_to_cart").sum()),
    checkout_status=('checkout', 'max')
)
X = user_features.drop(columns=['checkout_status'])
y = user_features['checkout_status']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
purchase_accuracy = accuracy_score(y_test, y_pred)

# --- COST-BENEFIT ANALYSIS ---
current_conversion_rate = (conversion_counts.get("checkout_completed", 0) / total_users) * 100
potential_revenue_increase = (industry_conversion_rate - current_conversion_rate) * total_users * 50  # Assuming $50 average order value

# --- HEATMAP & CLICKSTREAM ANALYSIS ---
df['hour'] = df['timestamp'].dt.hour
heatmap_data = df[df['event'].isin(['product_viewed', 'checkout_started', 'checkout_completed'])].pivot_table(index='hour', columns='event', aggfunc='size', fill_value=0)
sns.heatmap(heatmap_data, cmap='coolwarm', annot=True)
plt.title("User Interaction Heatmap by Hour")
plt.show()

# --- LLM-POWERED INSIGHTS ---
groq_llm = Groq(api_key="your_groq_api_key", model="llama-2-13b")

def generate_llm_insight(data_summary):
    """Uses Groq's Llama model to summarize key insights from customer behavior data."""
    prompt = PromptTemplate(
        input_variables=["data_summary"],
        template="""
        You are a data analyst for an e-commerce business. Summarize the key insights from customer behavior data.

        Data Summary:
        {data_summary}

        Provide actionable recommendations.
        """
    )
    return groq_llm(prompt.format(data_summary=data_summary))

statistical_summary = f"""
- Cart abandonment rate: {cart_abandonment_rate:.2f}% (Industry: {industry_cart_abandonment}%)
- Current conversion rate: {current_conversion_rate:.2f}% (Industry: {industry_conversion_rate}%)
- Predicted purchase likelihood accuracy: {purchase_accuracy:.2f}
- Potential revenue increase with AI intervention: ${potential_revenue_increase:,.2f}
"""

llm_insights = generate_llm_insight(statistical_summary)
print("\nAI-Generated Insights:", llm_insights)

# --- EXPERIMENT DESIGN ---
def generate_experiment_idea():
    """Uses Groq's Llama model to suggest an A/B test experiment for improving conversions."""
    prompt = PromptTemplate(
        template="""
        You are a data scientist designing an A/B test for an e-commerce chatbot.
        
        - Objective: Increase conversions for returning users and cart abandoners.
        - Control Group: No chatbot intervention.
        - Treatment Group: AI chatbot proactively engaging users at key decision points.

        Provide a structured experiment plan including hypothesis, method, and success criteria.
        """
    )
    return groq_llm(prompt.format())

experiment_plan = generate_experiment_idea()
print("\nAI-Generated Experiment Plan:", experiment_plan)
